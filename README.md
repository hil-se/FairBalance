 <a name=top>

[<img width=100% src="https://github.com/hil-se/hil-se/blob/main/img/bar.png?raw=yes">](https://github.com/hil-se/hil-se/blob/main/README.md) 
&nbsp;&nbsp;&nbsp;[HOME](https://github.com/hil-se/hil-se#top) &nbsp;&nbsp;&nbsp;|
&nbsp;&nbsp;&nbsp;[NEWS](https://github.com/hil-se/hil-se/blob/main/subs/news.md#top) &nbsp;&nbsp;&nbsp;|
&nbsp;&nbsp;&nbsp;[PEOPLE](https://github.com/hil-se/hil-se/blob/main/people/people.md#top) &nbsp;&nbsp;&nbsp;|
&nbsp;&nbsp;&nbsp;[PROJECTS](https://github.com/hil-se/hil-se/blob/main/subs/projects.md#top) &nbsp;&nbsp;&nbsp;|
&nbsp;&nbsp;&nbsp;[PAPERS](https://github.com/hil-se/hil-se/blob/main/subs/papers.md#top) &nbsp;&nbsp;&nbsp;|
&nbsp;&nbsp;&nbsp;[RESOURCES](https://github.com/hil-se/hil-se/blob/main/subs/resources.md#top) &nbsp;&nbsp;&nbsp;|
&nbsp;&nbsp;&nbsp;[CONTACT-US](https://github.com/hil-se/hil-se/blob/main/subs/contact.md#top) &nbsp;&nbsp;&nbsp;


## Projects

### Human Ethical Bias Detection with Machine Learning Software.

Aug 2021 | [repo](https://github.com/hil-se/fairness#top)

Instead of trying to reduce bias in machine learning software, this project aims to reduce bias from its source--- the human decisions.
 - That is, this work proposes to utilize the machine learning bias inherited from the training data (human decisions) as an indicator for detecting human bias.
 - While it is difficult to directly test whether a human has bias, with current research on machine learning bias, it is now easy to test, in large scale at low cost, whether a machine learning software has bias.
